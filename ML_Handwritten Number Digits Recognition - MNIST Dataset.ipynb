{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dat Do\n",
    "\n",
    "# Handwritten Number Digits Recognition\n",
    "\n",
    "# 8-6-18\n",
    "\n",
    "\n",
    "\n",
    "### About this notebook\n",
    "\n",
    "This is a Convolutional Neural Network I've created and trained in order to recognize number digits handwritten by people. I've tried to add a fair amount of commentary along the way in order to help visualize what is going on better. The dataset I'm utilizing is from the MNIST Database of Handwritten Digits which contains a training set of 60,000 28x28 examples and a test set of 10,000. The digits have been size-normalized and centered in a fixed-size image. I hope you'll learn something from this and please leave any thoughts or even suggestions that you may have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Dataset is provided through the 'torchdivision' package. In this CNN, the MNIST dataset is downloaded down below.\n",
    "# The batch size is 100 i.e. for each iteration, the model takes 100 images to feed through the convolutional layers, then through the fully connected layers.\n",
    "\n",
    "# Define a transform to normalize the data.\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "\n",
    "# Download and load the training data. Batch size equals 100.\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "\n",
    "# Download and load the test data. Batch size equals 100.\n",
    "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training data is loaded into 'trainloader'. Here, the iterator 'iter(trainloader)' loops through the first batch.\n",
    "# Images is a tensor with size (100, 1, 28, 28) i.e. 100 images per batch, 1 color channel, and 28x28 images.\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize.\n",
    "plt.imshow(images[99].numpy().squeeze(), cmap='Greys_r')\n",
    "print(\"Target: \", labels[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers).\n",
    "\n",
    "# First convolutional layer will have 1 input channel, 32 output channels (depth), kernel size of 5x5, stride of 1, and padding of 2.\n",
    "# Second convolutional layer will have 32 input channels, 64 output channels (depth), kernel size of 5x5, stride of 1, and padding of 2.\n",
    "# Max pooling operation with pooling size of 2x2 and stride of 2 to reduce the effective image size by a factor of 2.\n",
    "# First fully connected layer will have 7x7x64 nodes connecting to 1000 nodes.\n",
    "# Second fully connected layer will have 1000 nodes connecting to 10 nodes.\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_conv1=32, n_conv2=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_conv1, self.n_conv2 = n_conv1, n_conv2\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, self.n_conv1, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(self.n_conv1, self.n_conv2, kernel_size=5, stride=1, padding=2)\n",
    "        self.mp = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.drop_out = nn.Dropout()    # Drop-out layer to avoid over-fitting in the model.\n",
    "        self.fc1 = nn.Linear(7 * 7 * n_conv2, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "    \n",
    "    # Forward pass through the network to define how the data flows through the layers.\n",
    "    # Takes input argument of 'x'; data that is passed through the model i.e. a batch of data.\n",
    "    # conv_layer > ReLU_activation > max_pooling (x2) > flattening data into 1x3136 > fully_con_layer > ReLU_activation > fully_con_layer.\n",
    "    def forward(self, x):\n",
    "        out = self.mp(F.relu(self.conv1(x)))\n",
    "        out = self.mp(F.relu(self.conv2(out)))\n",
    "        out = out.view(-1, self.n_conv2 * 7 * 7)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of the ConvNet class.\n",
    "model = ConvNet()\n",
    "\n",
    "# Defining loss function and optimizer.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize intitial weights.\n",
    "print('Initial weights - ', model.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "# Train the model.\n",
    "running_loss= 0.0\n",
    "\n",
    "# Two loops - first, the number of epochs (1) is looped over, and within the loop, 'trainloader' is iterated over using 'enumerate'.\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # For each iteration (i) in trainloader (\"training dataset\"), \"batch_size\" of 100 images/labels would have been trained on.\n",
    "    # For example, 100 iterations in trainloader would mean that 10,000 images/labels have been used to train on. (100x100=10k).\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        # Run the forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backprop and perform Adam optimisation.\n",
    "        optimizer.zero_grad()    # Gradients are zeroed.\n",
    "        loss.backward()    # Perform back-propagation on 'loss'.\n",
    "        optimizer.step()    # Perform Adam optimizer training step once gradients have been calculated.\n",
    "        \n",
    "        # Track loss & accuracy.\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)    # Returns the index of the maximum value in a tensor i.e. Predictions of the model.\n",
    "        correct = (predicted == labels).sum().item()    # Perform comparisons between the Predictions and true Labels then sums them to determine number of correct predictions.\n",
    "        \n",
    "        # For every 100 iterations of the inner loop, progress is printed.\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(i)    # For reference. \n",
    "            print('[1, %d] Loss: %.5f Accuracy: %.3f' %\n",
    "                  (i + 1, running_loss / 100, (correct / total) * 100))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize updated weights.\n",
    "print('Updated weights - ', model.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model iterating over 'testloader'.\n",
    "\n",
    "i = 88\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "plt.imshow(images[i].numpy().squeeze(), cmap='Greys_r')\n",
    "print(\"Target: \", labels[i])\n",
    "\n",
    "outputs = model(images)\n",
    "\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print(\"Predicted:\", predicted[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
